---
title: "GLM Final Project"
author: "Hunter Kempf"
date: "3/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$set(root.dir = '/Users/hunterkempf/Documents/GitHub/Final_Project_GLM')
knitr::opts_knit$set(root.dir = '/Users/hk720x/Documents/GitHub/Final_Project_GLM/')

```

# Directions
The semester project gives you the chance to apply the knowledge and skills you will learn in the course in a way that mimics the ways you can expect to use logistic regression modeling in a real-world setting.

For the project, you will choose one data set from the two listed below and perform a logistic regression analysis. Specifically, you will build a regression model and report on the model statistics and diagnostics. Your final deliverable for the project will be an R Markdown file. The file will contain the analyses detailed in each step with 5-7 written bullet points. Basically, pretend you are presenting to a non-technical audience, and the bullet points would serve as a script outline for your explanation. By non-technical I mean an audience who knows things like “a p-value less than 0.05 mean statistical significance” but cannot really explain the underlying concepts in great detail.

You can choose one of two different data sets to complete the project, either the wine quality data set first analyzed during week 3 or the data set diabetes from
the faraway package, which we do not cover elsewhere in the course. Here are the details for each. Remember, you just need to choose one, not both.

* wine quality: rather than building a model to discriminate between white and red wine,
for the project you may collapse the quality variable into a binary response equal to 1
(high) if quality > 5 and 0 (low) if quality <= 5. Build a logistic regression model to
explain what factors are related to a high rating.

* diabetes: the help file for the data states that glycosolated hemoglobin (denoted
as glyhbin the data) greater than 7.0 is usually taken as a positive diagnosis of diabetes. Thus, collapse glyhb into a binary response equal to 1 if gly > 7 (positive) and 0 if gly <= 7 (negative). Build a logistic regression model to explain what factors are related to a positive diagnosis.


## Load Libraries 

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ROCR) # <-- for AUC 
library(ResourceSelection) # <-- for Hosmer-Lemeshow Goodness of Fit Test
library(splines) # <-- for splines 
```


## Read and Prepare Dataset


```{r message=FALSE, warning=FALSE}
wine_red <- read_delim('winequality-red.csv',delim = ';') %>% 
                    mutate(quality=factor(ifelse(quality>5,1,0),labels = c('low','high')))
names(wine_red)<-make.names(names(wine_red),unique = TRUE)
```

# Introduction

I am analyzing the red wine dataset for my final project. This dataset was collected in 2009 and includes objective sensor data and a subjective quality measure about Vinho Verde style red wine from Northern Portugal. The data has `r nrow(wine_red)` rows and `r ncol(wine_red)-1` physicochemical predictors and a single quality score from 0-10 which is the median score of at least 3 evaluations collected from wine experts. For simplicity I will be predicting if the score is high (greater than 5) or low (5 or less). The predictors are listed below :

1. fixed acidity (tartaric acid - g / dm^3)
    + most acids involved with wine or fixed or nonvolatile (do not evaporate readily)
2. volatile acidity (acetic acid - g / dm^3)
    + the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste
3. citric acid (g / dm^3)
    + found in small quantities, citric acid can add ‘freshness’ and flavor to wines
4. residual sugar (g / dm^3)
    + the amount of sugar remaining after fermentation stops, it’s rare to find wines with less than 1 gram/liter and wines with greater than 45 grams/liter are considered sweet
5. chlorides (sodium chloride - g / dm^3)
    +  the amount of salt in the wine
6. free sulfur dioxide (mg / dm^3)
    + the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine
7. total sulfur dioxide (mg / dm^3)
    + amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine
8. density (g / cm^3)
    + the density of wine is close to that of water depending on the percent alcohol and sugar content
9. pH
    + describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale
10. sulphates (potassium sulphate - g / dm3)
    + a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich acts as an antimicrobial and antioxidant
11. alcohol (% by volume)
    + the percent alcohol content of the wine

[Source for Variable Description](https://rstudio-pubs-static.s3.amazonaws.com/57835_c4ace81da9dc45438ad0c286bcbb4224.html)

These Predictors will be used with Logistic Regression modeling techniques to predict the subjective quality of the wine.

# Project Steps:

The project consists of five steps, which you will work on throughout the second half of the semester. The steps you complete each week will accumulate in your R Markdown file, due at the end of the course. You will receive credit for completing drafts of Steps 1- 5 according to the schedule below. Each of these steps are described in greater detail in the week they are due.

## Step 1: Exploratory Data Analysis (EDA)

* Task: Construct interleaved histograms and scatterplots to explore the relation between the predictors and response. Specifically, choose two predictors and make an interleaved histogram and scatterplot for each. Thus, you should construct four total graphs.

* Deliverables: 
  + Your code in Markdown should produce the plots.
  + Your 5-7 bullet points should explain the graphs including the axes and
what each plot means. Remember, interleaved histograms may be easy for you but maybe not so for others.

### Alcohol Percentage

```{r}
ggplot(
  data = wine_red,
  aes(x=alcohol,fill=quality)
) + geom_histogram(position = 'dodge',bins = 30) +
  ggtitle("Histogram of Wine Quality by Alcohol Percent")+
  xlab("Alcohol %")
```

### Total Sulfur Dioxide 

```{r}
ggplot(
  data = wine_red,
  aes(x=total.sulfur.dioxide,fill=quality)
) + geom_histogram(position = 'dodge',bins = 30) +
  ggtitle("Histogram of Wine Quality by Total Sulfur Dioxide") +
  xlab("Total Sulfur Dioxide")
```

### Scatterplot of Alcohol Percentage and Quality

```{r}
ggplot(
  data = wine_red,
  aes(x=total.sulfur.dioxide,y=quality,color=quality)
) + geom_jitter(alpha=.5) +
  ggtitle("Scatterplot of Wine Quality by Total Sulfur Dioxide") +
  xlab("Total Sulfur Dioxide")+
  ylab("Quality")
```

### Scatterplot of Total Sulfur Dioxide and Quality

```{r}
ggplot(
  data = wine_red,
  aes(x=alcohol,y=quality,color=quality)
) + geom_jitter(alpha=.5) +
  ggtitle("Scatterplot of Wine Quality by Alcohol %") +
  xlab("Alcohol %")+
  ylab("Quality")
```

### Graph Explanations

* Higher Alcohol Percentage is associated with better quality wines
* Lower Total Sulfur Dioxide is associated with better quality wines


## Step 2: Variable Selection

* Task: Perform variable selection via the AIC using the step() function. Your starting model should include all available predictors. The reduced model should be used as your final model for all subsequent steps. Or, if you disagree with the recommended model, you need to indicate why.

* Deliverables:
  + Your code in Markdown should show how you used the function, produce the results, and indicate your final model
  + Your bullet points should give a brief explanation of the algorithm and comment on the variables retained/removed from the model. Are the results intuitive?

### Create Binary Response Variable 

```{r}
wine_red <- wine_red %>% 
               mutate(quality=ifelse(quality=='high',1,0))
```

  
### Create Saturated Model

```{r}
saturated_model <- glm(quality~.,family=binomial,data=wine_red)
```

### Use step() to select paired down model

```{r}
aic_step <- step(saturated_model)
```

### Final Model Selected by step()

```{r}
formula(aic_step)
```


### Comments on Variables Selected:

* How the algorithm works:
  + Step starts with the saturated model and decides iteratively which variables it can remove
  + At each step it computes the AIC for a model with each single predictor removed as well as one for no predictors removed
  + If the model with a predictor removed gives a better AIC than one with no predictor removed step removes the predictor that gives the lowest AIC model it repeats this process until the model reaches a number of predictors where removing no predictor gives the lowest AIC
* Results: 
  + The results show that pH, residual sugar and density are not good predictors of quality with red wine. 
  + Also during the step process the removal of pH caused the fixed acidity variable to contribute more and become a relevant predictor since those variables are highly related.
  + Both of the variables I selected during my EDA section were relevant predictors and remained in the model
  
## Step 3: Assess Model Fit

* Task: Check that continuous predictors have a linear relation with the logit using loess plots and perform the Hosmer-Lemeshow (HL) goodness of fit test. If the loess plot is nonlinear, then splines should be used to account for the nonlinearity.

* Deliverables:
  + Your code in Markdown should show how you used the function, produce the results, and indicate your final model
  + Your bullet points should explain the axes of the loess plot, the conclusion of the loess plot, the basic concepts of the HL test, and its result. If the HL test reveals poor fit, this should be discussed.

### Loess Plot

```{r}
loess_plot <- function(column_name){
  f <- as.formula(paste("quality", column_name, sep = " ~ "))
  y_smooth <- predict(loess(f, data=wine_red))
  zero_one <- which(y_smooth>0 & y_smooth<1)

  plot(jitter(wine_red[[column_name]])[zero_one],log(y_smooth[zero_one]/(1-y_smooth[zero_one])),
       xlab = column_name)
}
```


#### Alcohol 
```{r}
loess_plot('alcohol')
```

The lowess plot for Alcohol clearly shows around 2 splines around 9.5% and 12.5%
  
#### Volatile Acidity 
```{r}
loess_plot('volatile.acidity')
```

The lowess plot for Volatile Acidity does not show a strong need for splines

#### Sulphates 
```{r}
loess_plot('sulphates')
```

The lowess plot for Sulphates shows a clear need for a spline around 1 

#### Total Sulfur Dioxide 
```{r}
loess_plot('total.sulfur.dioxide')
```

The lowess plot for Total Sulfur Dioxide shows a potential spline around 40 is needed 

#### Free Sulfur Dioxide
```{r}
loess_plot('free.sulfur.dioxide')
```

The lowess plot for Free Sulfur Dioxide shows splines around 10 and 15 could improve the model

#### Fixed Acidity 
```{r}
loess_plot('fixed.acidity')
```

The lowess plot for Fixed Acidity shows that splines around 8 and 12 are needed 

#### Chlorides 
```{r}
loess_plot('chlorides')
```

The lowess plot for Chlorides shows a spline around .09 should be added

#### Citric Acid 
```{r}
loess_plot('citric.acid')
```

The lowess plot for Citric Acid shows that splines around .2 and .5 should be added 

### Adding Splines

```{r}
spline_formula <- formula(quality~ns(citric.acid,4)+
                                  ns(chlorides,2)+
                                  ns(fixed.acidity,2)+
                                  ns(free.sulfur.dioxide,4)+
                                  ns(total.sulfur.dioxide,3)+
                                  ns(sulphates,4)+
                                  volatile.acidity+
                                  ns(alcohol,4))
step_with_splines_model <- glm(spline_formula,family=binomial,data=wine_red)
```


### Hosmer-Lemeshow Goodness of Fit Test

#### Model without Splines 
```{r}
hl_test <- hoslem.test(wine_red$quality,aic_step$fitted.values,10)
hl_test
```

#### Model with Splines 
```{r}
hl_test <- hoslem.test(wine_red$quality,step_with_splines_model$fitted.values,10)
hl_test
```

### Comments on Loess Plot and HL GoF Test:

* Most of the Loess Plots show that the predictors are nonlinear except Volatile Acidity and thus splines need to be used to create multiple regression lines for each of the remaining predictors in the model. Another choice could be to select a model like a decision tree or neural network that can model features with nonlinear behaviors

* HL Tests
  + The HL test on the model fit with the step() function shows that the model fit is not adequate. This is likely due to the fact that the predictors are mostly non-linear.
  + After adding splines the model fit shows that it is adequate

## Step 4: Model Inferences

* Task: Report p-values and confidence intervals for significant predictors and check for influential observations. Any influential observations should be removed and the model should be refit. Note any changes in the inferences due to the removal.

* Deliverables:
  + Your code in Markdown should show how you used the function, produce the results, and indicate your final model
  + Your bullet points should give practical interpretation of the inferences and explain the process of checking for influential observations.

### Confidence Intervals and p-values
```{r message=FALSE, warning=FALSE}
conf_int <- confint(step_with_splines_model) %>% 
              data.frame() %>%
              rownames_to_column(var="Predictors")

p.values <- step_with_splines_model%>% 
              summary() %>%
              coef()%>% 
              .[,4] %>% 
              data.frame()%>%
              rownames_to_column(var="Predictors") 
colnames(p.values) <- c("Predictors", "p.values")
conf_int %>% left_join(p.values)
```

### Influential Observations

Get Cooks Distances
```{r}
CooksDistance <- cooks.distance(step_with_splines_model)
summary(CooksDistance)
```

Count Cooks Distances above the suggested threshold of 1
```{r}
sum(CooksDistance > 1)
```

Count Cooks Distances above the other suggested threshold of 4/length(df)
```{r}
sum(CooksDistance > 4/length(wine_red))
```

Plot of the model fitted values (x-axis) versus the Cooks Distance values (y-axis). Any points lying far above the others should be investigated.
```{r}
ggplot(
  data = data.frame(model_fitted_values = step_with_splines_model$fitted.values,
                    Cooks_Distance = CooksDistance),
  aes(x = model_fitted_values,y = Cooks_Distance)
) + geom_point()
```


### Comments on Inferences and Influential Observations:

* After Adding splines a fair ammount of the parameters have 95% confidence intervals that include 0. This seems to be an artifact of the splines and per spline there is genrally a parameter with a parameter CI that does not include 0

* Influential Observations:
  + There are no influential observations by looking at the Cooks Distance with either of the suggested thresholds
  + A plot of the Cooks Distance and Model Fitted values shows a point with a cooks distance of ~.08 this distance is too small to be influential to the model though

## 5: Asses Predictive Power

* Task: Summarize predictive/discriminatory power of the model with an ROC curve and plots of predicted probabilities.

* Deliverables:
  + Your code in Markdown should show how you used the function, produce the results, and indicate your final model
  + Your bullet points should give a brief explanation of each plot and the
interpretation for your model.

### Plot ROC Curve
```{r}
pred <- prediction(step_with_splines_model$fitted.values, wine_red$quality)
perf <- performance(pred, measure = "tpr", x.measure = "fpr") 
plot(perf, col=rainbow(10), main="ROC Curve")
```

### Determine AUC

```{r}
auc.tmp <- performance(pred,"auc"); 
auc <- as.numeric(auc.tmp@y.values)
cat(paste("The AUC for my selected model is:",round(auc,3)))
```

### Histogram of Fitted Values 

```{r}
hist(step_with_splines_model$fitted.values,
     main="Histogram of Model Predicted Values", 
     xlab="Predicted Values")
```


### Plot Predicted Probabilities by Predictor

```{r}
plot(wine_red$fixed.acidity,step_with_splines_model$fitted.values)
```

```{r}
plot(wine_red$volatile.acidity,step_with_splines_model$fitted.values)
```

```{r}
plot(wine_red$citric.acid,step_with_splines_model$fitted.values)
```

```{r}
plot(wine_red$chlorides,step_with_splines_model$fitted.values)
```

```{r}
plot(wine_red$free.sulfur.dioxide,step_with_splines_model$fitted.values)
```

```{r}
plot(wine_red$total.sulfur.dioxide,step_with_splines_model$fitted.values)
```

```{r}
plot(wine_red$sulphates,step_with_splines_model$fitted.values)
```

```{r}
plot(wine_red$alcohol,step_with_splines_model$fitted.values)
```

### Comments on Plots and Model Interpretation:

* Analysis of ROC Curve Plot and AUC
  + The ROC Curve is up and to the left with an AUC of ~.84 which suggests that the model fits the data well and we would classify the model as Excellent using the AUC interpretation shown in class.
  + The AUC shown here is on the same data that the model was trained on so it may overinflate the predictive power that the model actually has. To understand this more we would have to split the data into training and test sets then calculate the AUC for both.

* Analysis of Plots of Fitted Values by Predictor
  + One of the most striking plots is the last one, Alcohol, as alcohol percentage increases generally our model will predict that the wine is of good quality. 
  + Other plots like chlorides generally dont seem to be predictive for most wines but show that deviating off the .1 value generally leads to a wine with a lower predicted value

# Conclusion

I built a model that describes the wine quality well enough. The Spline's added to all but one predictors in the final model were invaluable. The ROC AUC jumped from ~0.17 to ~0.84 due to their addition. Many of the predictors seem to behave with higher order terms which were modeled with splines but it would have been interesting to look at higher order or interaction terms between the variables. There are some other objective predictors I would be interested in adding such as price per bottle, age of the wine, type of grapes used and wine brand information. Sadly all this information is not public with the dataset. I would be interested in getting data about the public's scores for the wines tested and see if those scores generally track the scores that the experts gave each wine. 

A Dataset like this could be used to help predict wines and characteristics of wines that will be successful on the market before any human even tests them. This can help wineries to produce better quality wines that taste better. Also if an individual tasted and scored many of these wines their individual preferences could be encoded into a model that could help them to select similar wines to wines that they have enjoyed before.